{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data do datasetu s 5minutovým intervalem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data z FVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "df_generation = pd.read_csv(\"data\\solax\\datacsvnaexport_final.csv\", sep = \";\")\n",
    "df_generation['update time'] = df_generation['update time'].str.rstrip('.')\n",
    "df_generation['timestamp'] = pd.to_datetime(df_generation['update time'], format='%Y-%m-%d %H:%M:%S', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data z meteostanic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "primary_df = pd.read_csv('data\\wunderground\\IVELKO9.csv')\n",
    "secondary_df = pd.read_csv('data\\wunderground\\IPODBR33.csv')\n",
    "\n",
    "# pridan nazev stanice\n",
    "primary_df = primary_df.assign(dataset='IVELKO9')\n",
    "secondary_df = secondary_df.assign(dataset='IPODBR33')\n",
    "\n",
    "# vytvoren timestamp sloupec\n",
    "primary_df['timestamp'] = primary_df['Date'] + ' ' + primary_df['Time']\n",
    "secondary_df['timestamp'] = secondary_df['Date'] + ' ' + secondary_df['Time']\n",
    "# konvert\n",
    "primary_df['timestamp'] = pd.to_datetime(primary_df['timestamp'], format='%Y/%m/%d %I:%M %p', errors='coerce')\n",
    "secondary_df['timestamp'] = pd.to_datetime(secondary_df['timestamp'], format='%Y/%m/%d %I:%M %p', errors='coerce')\n",
    "# drop NAT\n",
    "primary_df = primary_df.dropna(subset=['timestamp'])\n",
    "secondary_df = secondary_df.dropna(subset=['timestamp'])\n",
    "# zaokrouhleno\n",
    "primary_df[\"rounded_timestamp\"] = primary_df[\"timestamp\"].dt.round(\"5min\")\n",
    "secondary_df[\"rounded_timestamp\"] = secondary_df[\"timestamp\"].dt.round(\"5min\")\n",
    "\n",
    "# reseni missing values vypadku stanic a concat\n",
    "primary_mask = primary_df['Temperature_C'].isna()\n",
    "missing_timestamps = primary_df.loc[primary_mask, 'rounded_timestamp']\n",
    "secondary_subset = secondary_df[secondary_df['rounded_timestamp'].isin(missing_timestamps)]\n",
    "merged_df = pd.concat([primary_df, secondary_subset], ignore_index=True)\n",
    "\n",
    "# seřadit podle rounded_timestamp pro časovou posloupnost\n",
    "merged_df = merged_df.sort_values('rounded_timestamp')\n",
    "\n",
    "#drop zbytečné sloupce\n",
    "merged_df_dropped = merged_df.drop(columns=['Date','Time',])\n",
    "\n",
    "# rounded_timestamp na index0 pro přehlednost\n",
    "cols = list(merged_df_dropped.columns)\n",
    "cols.insert(0, cols.pop(cols.index('rounded_timestamp')))\n",
    "merged_df_dropped = merged_df.loc[:, cols]\n",
    "\n",
    "\n",
    "df_weather = merged_df_dropped.dropna(subset=['Temperature_C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_19528\\2634146420.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_19528\\2634146420.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_weather['timestamp_rounded'] = df_weather['timestamp'].apply(lambda x: custom_rounding(x, 5))\n"
     ]
    }
   ],
   "source": [
    "df_reference = pd.read_csv('data_final/reference_table.csv')\n",
    "#df_consumption = pd.read_csv('data/cez_data_elektromer/pnd_spotreba3.csv',sep = \";\", encoding='ISO-8859-1')\n",
    "\n",
    "\n",
    "df_generation.drop(['EPS active power R(W)','EPS active power S(W)','EPS active power T(W)','EPS apparent power R(VA)','EPS apparent power S(VA)'\n",
    "                    ,'EPS apparent power T(VA)'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Custom rounding function\n",
    "def custom_rounding(timestamp, interval):\n",
    "    \"\"\"\n",
    "    Custom rounding function that rounds timestamps to the nearest interval and sets seconds to zero.\n",
    "    Breaks ties by rounding down.\n",
    "    \n",
    "    :param timestamp: The original timestamp.\n",
    "    :param interval: The interval to round to, in minutes.\n",
    "    :return: The rounded timestamp with seconds set to zero.\n",
    "    \"\"\"\n",
    "    # Convert interval to a timedelta\n",
    "    delta = timedelta(minutes=interval)\n",
    "    \n",
    "    # Find the remainder when dividing the timestamp by the interval\n",
    "    remainder = timestamp.minute % interval\n",
    "    \n",
    "    # If the remainder is less than half the interval, round down\n",
    "    if remainder < interval / 2:\n",
    "        rounded = timestamp - timedelta(minutes=remainder)\n",
    "    # If the remainder is exactly half the interval, also round down\n",
    "    elif remainder == interval / 2:\n",
    "        rounded = timestamp - timedelta(minutes=remainder)\n",
    "    # Otherwise, round up\n",
    "    else:\n",
    "        rounded = timestamp + (delta - timedelta(minutes=remainder))\n",
    "    \n",
    "    # Set seconds (and microseconds) to zero\n",
    "    return rounded.replace(second=0, microsecond=0)\n",
    "\n",
    "# Convert timestamps to datetime and set as index\n",
    "df_reference['timestamp'] = pd.to_datetime(df_reference['datetime'])\n",
    "df_generation['timestamp'] = pd.to_datetime(df_generation['timestamp'])\n",
    "df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
    "#df_consumption['timestamp'] = pd.to_datetime(df_consumption['Datum'], dayfirst=True)\n",
    "\n",
    "df_generation['timestamp_rounded'] = df_generation['timestamp'].apply(lambda x: custom_rounding(x, 5))\n",
    "df_weather['timestamp_rounded'] = df_weather['timestamp'].apply(lambda x: custom_rounding(x, 5))\n",
    "\n",
    "df_reference.set_index('timestamp', inplace=True)\n",
    "df_generation.set_index('timestamp_rounded', inplace=True)\n",
    "df_weather.set_index('timestamp_rounded', inplace=True)\n",
    "#df_consumption.set_index('timestamp', inplace=True)\n",
    "\n",
    "df_merged_with_reference = pd.merge(df_reference, df_generation, how='left', left_index=True, right_index=True)\n",
    "df_final_merged = pd.merge(df_merged_with_reference, df_weather, how='left', left_index=True, right_index=True)\n",
    "\n",
    "df_final_merged.index.name = 'timestamp'\n",
    "df_final_merged.drop(['update time','timestamp_x','rounded_timestamp','timestamp_y','datetime'], axis=1, inplace=True)\n",
    "\n",
    "df_final_merged.to_csv(\"merged_5min.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vytvoření datasetu s intervaly 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df_final_merged['daily yield(kWh)'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_merged['consume energy(kWh)'] = df_final_merged['consume energy(kWh)'].str.replace(',', '.').astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_19528\\1079598414.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Temperature_C'] = pd.to_numeric(df_filtered['Temperature_C'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            daily yield(kWh)  PV1 input power(W)  PV2 input power(W)  \\\n",
      "timestamp                                                              \n",
      "2023-03-16              22.6              3837.0              3634.0   \n",
      "2023-03-17              20.5              3440.0              4075.0   \n",
      "2023-03-18              22.1              3751.0              3689.0   \n",
      "2023-03-19              24.4              4075.0              3288.0   \n",
      "2023-03-20              17.3              4230.0              3892.0   \n",
      "\n",
      "           peak_production_time peak_PV1_production_time  \\\n",
      "timestamp                                                  \n",
      "2023-03-16             14:50:00                 13:20:00   \n",
      "2023-03-17             15:05:00                 10:00:00   \n",
      "2023-03-18             11:30:00                 12:45:00   \n",
      "2023-03-19             11:15:00                 12:25:00   \n",
      "2023-03-20             18:00:00                 11:40:00   \n",
      "\n",
      "           peak_PV2_production_time  average_temperature total_precipitation  \\\n",
      "timestamp                                                                      \n",
      "2023-03-16                 09:10:00             2.342160                0.25   \n",
      "2023-03-17                 10:00:00             6.111150                 0.0   \n",
      "2023-03-18                 10:45:00             7.050140                 0.0   \n",
      "2023-03-19                 12:10:00             8.113846                 0.0   \n",
      "2023-03-20                 11:40:00             9.513868                 0.0   \n",
      "\n",
      "            daily_consumption  daily_feed_in_energy  \n",
      "timestamp                                            \n",
      "2023-03-16              13.47                   0.1  \n",
      "2023-03-17               9.46                   0.0  \n",
      "2023-03-18               9.85                   0.1  \n",
      "2023-03-19               6.84                   0.1  \n",
      "2023-03-20               6.11                   0.0  \n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary with the resampling method for each column\n",
    "resample_dict = {\n",
    "    'daily yield(kWh)': 'max',\n",
    "    'consume energy(kWh)': 'last',\n",
    "    'feed-in energy(kWh)': 'last',\n",
    "    'PV1 input power(W)': 'max',\n",
    "    'PV2 input power(W)': 'max',\n",
    "    'feed-in power(W)': 'min',\n",
    "    'feed-in power(W)': 'max',\n",
    "    # Add other columns and their respective methods here\n",
    "}\n",
    "\n",
    "# Resample the DataFrame using the specified dictionary\n",
    "df_filtered = df_final_merged.between_time('00:05', '23:55')\n",
    "daily_df = df_filtered.resample('D').agg(resample_dict)\n",
    "\n",
    "df_filtered['Temperature_C'] = pd.to_numeric(df_filtered['Temperature_C'], errors='coerce')\n",
    "\n",
    "daily_df['peak_production_time'] = df_filtered['output power(W)'].resample('D').apply(lambda x: x.idxmax().time())\n",
    "daily_df['peak_PV1_production_time'] = df_filtered['PV1 input power(W)'].resample('D').apply(lambda x: x.idxmax().time())\n",
    "daily_df['peak_PV2_production_time'] = df_filtered['PV2 input power(W)'].resample('D').apply(lambda x: x.idxmax().time())\n",
    "daily_df[''] = df_filtered['PV1 input power(W)'].resample('D').apply(lambda x: x.idxmax().time())\n",
    "daily_df['average_temperature'] = df_filtered['Temperature_C'].resample('D').mean()\n",
    "daily_df['total_precipitation'] = df_filtered['Precip_Accum_mm'].resample('D').last()\n",
    "\n",
    "# For the consumed and feed-in energy, subtract the first value of the day from the last value\n",
    "daily_df['daily_consumption'] = daily_df['consume energy(kWh)'] - df_final_merged['consume energy(kWh)'].resample('D').first()\n",
    "daily_df['daily_feed_in_energy'] = daily_df['feed-in energy(kWh)'] - df_final_merged['feed-in energy(kWh)'].resample('D').first()\n",
    "\n",
    "# Drop the original 'last' columns as they are no longer needed after the subtraction\n",
    "daily_df.drop(columns=['consume energy(kWh)', 'feed-in energy(kWh)'], inplace=True)\n",
    "\n",
    "print(daily_df.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
