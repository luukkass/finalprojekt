{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data do datasetu s 5minutovým intervalem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data z FVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "df_generation = pd.read_csv(\"data\\solax\\datacsvnaexport_final.csv\", sep = \";\")\n",
    "df_generation['update time'] = df_generation['update time'].str.rstrip('.')\n",
    "df_generation['timestamp'] = pd.to_datetime(df_generation['update time'], format='%Y-%m-%d %H:%M:%S', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data z meteostanic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "primary_df = pd.read_csv('data\\wunderground\\IVELKO9.csv')\n",
    "secondary_df = pd.read_csv('data\\wunderground\\IPODBR33.csv')\n",
    "\n",
    "# pridan nazev stanice\n",
    "primary_df = primary_df.assign(dataset='IVELKO9')\n",
    "secondary_df = secondary_df.assign(dataset='IPODBR33')\n",
    "\n",
    "# vytvoren timestamp sloupec\n",
    "primary_df['timestamp'] = primary_df['Date'] + ' ' + primary_df['Time']\n",
    "secondary_df['timestamp'] = secondary_df['Date'] + ' ' + secondary_df['Time']\n",
    "# konvert\n",
    "primary_df['timestamp'] = pd.to_datetime(primary_df['timestamp'], format='%Y/%m/%d %I:%M %p', errors='coerce')\n",
    "secondary_df['timestamp'] = pd.to_datetime(secondary_df['timestamp'], format='%Y/%m/%d %I:%M %p', errors='coerce')\n",
    "# drop NAT\n",
    "primary_df = primary_df.dropna(subset=['timestamp'])\n",
    "secondary_df = secondary_df.dropna(subset=['timestamp'])\n",
    "# zaokrouhleno\n",
    "primary_df[\"rounded_timestamp\"] = primary_df[\"timestamp\"].dt.round(\"5min\")\n",
    "secondary_df[\"rounded_timestamp\"] = secondary_df[\"timestamp\"].dt.round(\"5min\")\n",
    "\n",
    "# reseni missing values vypadku stanic a concat\n",
    "primary_mask = primary_df['Temperature_C'].isna()\n",
    "missing_timestamps = primary_df.loc[primary_mask, 'rounded_timestamp']\n",
    "secondary_subset = secondary_df[secondary_df['rounded_timestamp'].isin(missing_timestamps)]\n",
    "merged_df = pd.concat([primary_df, secondary_subset], ignore_index=True)\n",
    "\n",
    "# seřadit podle rounded_timestamp pro časovou posloupnost\n",
    "merged_df = merged_df.sort_values('rounded_timestamp')\n",
    "\n",
    "#drop zbytečné sloupce\n",
    "merged_df_dropped = merged_df.drop(columns=['Date','Time',])\n",
    "\n",
    "# rounded_timestamp na index0 pro přehlednost\n",
    "cols = list(merged_df_dropped.columns)\n",
    "cols.insert(0, cols.pop(cols.index('rounded_timestamp')))\n",
    "merged_df_dropped = merged_df.loc[:, cols]\n",
    "\n",
    "\n",
    "df_weather = merged_df_dropped.dropna(subset=['Temperature_C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spojení dataset\n",
    "Napojovat se bude na timestamp, takže je provedeno zaokrouhlení na 5min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_19528\\589364323.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_19528\\589364323.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_weather['timestamp_rounded'] = df_weather['timestamp'].apply(lambda x: custom_rounding(x, 5))\n"
     ]
    }
   ],
   "source": [
    "df_reference = pd.read_csv('data_final/reference_table.csv')\n",
    "#df_consumption = pd.read_csv('data/cez_data_elektromer/pnd_spotreba3.csv',sep = \";\", encoding='ISO-8859-1')\n",
    "\n",
    "\n",
    "df_generation.drop(['EPS active power R(W)','EPS active power S(W)','EPS active power T(W)','EPS apparent power R(VA)','EPS apparent power S(VA)'\n",
    "                    ,'EPS apparent power T(VA)'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# fce na zaokrouhlení\n",
    "def custom_rounding(timestamp, interval):\n",
    "    delta = timedelta(minutes=interval)\n",
    "    remainder = timestamp.minute % interval\n",
    "    if remainder < interval / 2:\n",
    "        rounded = timestamp - timedelta(minutes=remainder)\n",
    "    elif remainder == interval / 2:\n",
    "        rounded = timestamp - timedelta(minutes=remainder)\n",
    "    else:\n",
    "        rounded = timestamp + (delta - timedelta(minutes=remainder))\n",
    "    return rounded.replace(second=0, microsecond=0)\n",
    "\n",
    "# timestamp na datetime format\n",
    "df_reference['timestamp'] = pd.to_datetime(df_reference['datetime'])\n",
    "df_generation['timestamp'] = pd.to_datetime(df_generation['timestamp'])\n",
    "df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
    "\n",
    "#call rounding fce\n",
    "df_generation['timestamp_rounded'] = df_generation['timestamp'].apply(lambda x: custom_rounding(x, 5))\n",
    "df_weather['timestamp_rounded'] = df_weather['timestamp'].apply(lambda x: custom_rounding(x, 5))\n",
    "\n",
    "df_reference.set_index('timestamp', inplace=True)\n",
    "df_generation.set_index('timestamp_rounded', inplace=True)\n",
    "df_weather.set_index('timestamp_rounded', inplace=True)\n",
    "\n",
    "df_merged_with_reference = pd.merge(df_reference, df_generation, how='left', left_index=True, right_index=True)\n",
    "df_final_merged = pd.merge(df_merged_with_reference, df_weather, how='left', left_index=True, right_index=True)\n",
    "\n",
    "df_final_merged.index.name = 'timestamp'\n",
    "\n",
    "#drop nepotrebnych\n",
    "df_final_merged.drop(['update time','timestamp_x','rounded_timestamp','timestamp_y','datetime'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vytvoření datasetu s intervaly 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[0;32m   1493\u001b[0m         how,\n\u001b[0;32m   1494\u001b[0m         axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1495\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:959\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[1;32m--> 959\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[0;32m    960\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[0;32m    961\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    962\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    963\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    964\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    966\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:657\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[0;32m    650\u001b[0m         values,\n\u001b[0;32m    651\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    655\u001b[0m     )\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_op_ndim_compat(\n\u001b[0;32m    658\u001b[0m     values,\n\u001b[0;32m    659\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    660\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    661\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    662\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    664\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:482\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m     result_mask \u001b[38;5;241m=\u001b[39m result_mask[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m--> 482\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_cython_op(\n\u001b[0;32m    483\u001b[0m     values2d,\n\u001b[0;32m    484\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    485\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    486\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    487\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    488\u001b[0m     result_mask\u001b[38;5;241m=\u001b[39mresult_mask,\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    490\u001b[0m )\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[1;32m--> 541\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow, values\u001b[38;5;241m.\u001b[39mdtype, is_numeric)\n\u001b[0;32m    542\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:173\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[1;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39m__signatures__:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction is not implemented for this dtype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->max,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# resample\u001b[39;00m\n\u001b[0;32m     13\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df_final_merged\u001b[38;5;241m.\u001b[39mbetween_time(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m00:05\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m23:55\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m daily_df \u001b[38;5;241m=\u001b[39m df_filtered\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg(resample_dict)\n\u001b[0;32m     16\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemperature_C\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemperature_C\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m daily_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_production_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput power(W)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39midxmax()\u001b[38;5;241m.\u001b[39mtime())\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\resample.py:329\u001b[0m, in \u001b[0;36mResampler.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m    322\u001b[0m     _shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    323\u001b[0m     see_also\u001b[38;5;241m=\u001b[39m_agg_see_also_doc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    327\u001b[0m )\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 329\u001b[0m     result \u001b[38;5;241m=\u001b[39m ResamplerWindowApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    331\u001b[0m         how \u001b[38;5;241m=\u001b[39m func\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:163\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(arg):\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:420\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    417\u001b[0m         results \u001b[38;5;241m=\u001b[39m {key: colg\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m         results \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    421\u001b[0m             key: obj\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    422\u001b[0m         }\n\u001b[0;32m    424\u001b[0m \u001b[38;5;66;03m# set the final keys\u001b[39;00m\n\u001b[0;32m    425\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(arg\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:421\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    417\u001b[0m         results \u001b[38;5;241m=\u001b[39m {key: colg\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[0;32m    420\u001b[0m         results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 421\u001b[0m             key: obj\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    422\u001b[0m         }\n\u001b[0;32m    424\u001b[0m \u001b[38;5;66;03m# set the final keys\u001b[39;00m\n\u001b[0;32m    425\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(arg\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:232\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, func)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2314\u001b[0m, in \u001b[0;36mGroupBy.max\u001b[1;34m(self, numeric_only, min_count, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_min_max, engine_kwargs, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_general(\n\u001b[0;32m   2315\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2316\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   2317\u001b[0m         alias\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2318\u001b[0m         npfunc\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax,\n\u001b[0;32m   2319\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1422\u001b[0m, in \u001b[0;36mGroupBy._agg_general\u001b[1;34m(self, numeric_only, min_count, alias, npfunc)\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_agg_general\u001b[39m(\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1420\u001b[0m     npfunc: Callable,\n\u001b[0;32m   1421\u001b[0m ):\n\u001b[1;32m-> 1422\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1423\u001b[0m         how\u001b[38;5;241m=\u001b[39malias,\n\u001b[0;32m   1424\u001b[0m         alt\u001b[38;5;241m=\u001b[39mnpfunc,\n\u001b[0;32m   1425\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1426\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   1427\u001b[0m     )\n\u001b[0;32m   1428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1507\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1508\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1509\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\base.py:197\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[0;32m    196\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[1;32m--> 197\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(arr)\n\u001b[0;32m    198\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[0;32m    200\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1503\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m-> 1503\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1457\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     ser \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;66;03m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;66;03m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;66;03m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[1;32m-> 1457\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, Categorical):\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;66;03m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;66;03m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m     \u001b[38;5;66;03m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(values)\u001b[38;5;241m.\u001b[39m_from_sequence(res_values, dtype\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    996\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1012\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m   1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(res)\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2820\u001b[0m, in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2703\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[0;32m   2704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mamax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2705\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2706\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2707\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   2708\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2818\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[0;32m   2819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39mmaximum, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out,\n\u001b[0;32m   2821\u001b[0m                           keepdims\u001b[38;5;241m=\u001b[39mkeepdims, initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:84\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11646\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.max\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11627\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11628\u001b[0m     _num_doc,\n\u001b[0;32m  11629\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the maximum of the values over the requested axis.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11644\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11645\u001b[0m ):\n\u001b[1;32m> 11646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11185\u001b[0m, in \u001b[0;36mNDFrame.max\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\n\u001b[0;32m  11179\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11180\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11183\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11184\u001b[0m ):\n\u001b[1;32m> 11185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11186\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m  11187\u001b[0m         nanops\u001b[38;5;241m.\u001b[39mnanmax,\n\u001b[0;32m  11188\u001b[0m         axis,\n\u001b[0;32m  11189\u001b[0m         skipna,\n\u001b[0;32m  11190\u001b[0m         numeric_only,\n\u001b[0;32m  11191\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11192\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11159\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11160\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4670\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   4666\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4668\u001b[0m     )\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    156\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 421\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    424\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1094\u001b[0m, in \u001b[0;36m_nanminmax.<locals>.reduction\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1092\u001b[0m         result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1094\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(values, meth)(axis)\n\u001b[0;32m   1096\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_null_out(result, axis, mask, values\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:41\u001b[0m, in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_maximum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "# dict na resampling metodu\n",
    "resample_dict = {\n",
    "    'daily yield(kWh)': 'max',\n",
    "    'consume energy(kWh)': 'last',\n",
    "    'feed-in energy(kWh)': 'last',\n",
    "    'PV1 input power(W)': 'max',\n",
    "    'PV2 input power(W)': 'max',\n",
    "    'feed-in power(W)': 'min',\n",
    "    'feed-in power(W)': 'max',\n",
    "}\n",
    "\n",
    "# resample\n",
    "df_filtered = df_final_merged.between_time('00:05', '23:55')\n",
    "daily_df = df_filtered.resample('D').agg(resample_dict)\n",
    "\n",
    "df_filtered['Temperature_C'] = pd.to_numeric(df_filtered['Temperature_C'], errors='coerce')\n",
    "\n",
    "daily_df['peak_production_time'] = df_filtered['output power(W)'].resample('D').apply(lambda x: x.idxmax().time())\n",
    "daily_df['peak_PV1_production_time'] = df_filtered['PV1 input power(W)'].resample('D').apply(lambda x: x.idxmax().time())\n",
    "daily_df['peak_PV2_production_time'] = df_filtered['PV2 input power(W)'].resample('D').apply(lambda x: x.idxmax().time())\n",
    "daily_df['peak_feed_inpower_time'] = df_filtered['feed-in power(W)'].resample('D').apply(lambda x: x.idxmax().time())\n",
    "daily_df['low_feed_inpower_time'] = df_filtered['feed-in power(W)'].resample('D').apply(lambda x: x.idxmin().time())\n",
    "daily_df['average_temperature'] = df_filtered['Temperature_C'].resample('D').mean()\n",
    "daily_df['total_precipitation'] = df_filtered['Precip_Accum_mm'].resample('D').last()\n",
    "\n",
    "# kalkulace feature\n",
    "daily_df['daily_consumption'] = daily_df['consume energy(kWh)'] - df_final_merged['consume energy(kWh)'].resample('D').first()\n",
    "daily_df['daily_feed_in_energy'] = daily_df['feed-in energy(kWh)'] - df_final_merged['feed-in energy(kWh)'].resample('D').first()\n",
    "\n",
    "# drop zbytecnychy\n",
    "daily_df.drop(columns=['consume energy(kWh)', 'feed-in energy(kWh)'], inplace=True)\n",
    "\n",
    "daily_df.to_csv(\"daily.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kategorizace atributu pro CleverMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'PV1 voltage (V)', 'PV1 current (A)', 'PV1 input power(W)',\n",
      "       'PV2 voltage (V)', 'PV2 current (A)', 'PV2 input power(W)',\n",
      "       'AC current R(A)', 'AC voltage R(V)', 'AC current S(A)',\n",
      "       'AC voltage S(V)', 'AC current T(A)', 'AC voltage T(V)',\n",
      "       'output power(W)', 'feed-in power(W)', 'daily yield(kWh)',\n",
      "       'total yield(kWh)', 'feed-in energy(kWh)', 'consume energy(kWh)',\n",
      "       'Inverter Status', 'Battery operating status', 'Temperature_C',\n",
      "       'Dew_Point_C', 'Humidity_%', 'Wind', 'Speed_kmh', 'Gust_kmh',\n",
      "       'Pressure_hPa', 'Precip_Rate_mm', 'Precip_Accum_mm', 'UV', 'Solar_w/m2',\n",
      "       'dataset'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('merged_5min.csv')\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sjednocení formátu float values\n",
    "Některé features měly decimal oddělený \",\" a některé \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['PV1 voltage (V)', 'PV1 current (A)', 'PV1 input power(W)',\n",
    "       'PV2 voltage (V)', 'PV2 current (A)', 'PV2 input power(W)',\n",
    "       'AC current R(A)', 'AC voltage R(V)', 'AC current S(A)',\n",
    "       'AC voltage S(V)', 'AC current T(A)', 'AC voltage T(V)',\n",
    "       'output power(W)', 'feed-in power(W)', 'daily yield(kWh)',\n",
    "       'total yield(kWh)', 'feed-in energy(kWh)', 'consume energy(kWh)',\n",
    "       'Temperature_C', 'Dew_Point_C', 'Humidity_%', 'Speed_kmh', 'Gust_kmh',\n",
    "       'Pressure_hPa', 'Precip_Rate_mm', 'Precip_Accum_mm', 'UV', 'Solar_w/m2']\n",
    "\n",
    "\n",
    "def replace_zeros(value):\n",
    "    if isinstance(value, str):\n",
    "        if value.strip() == '0':\n",
    "            return '0.0'\n",
    "        return value.replace(',', '.')\n",
    "    return value\n",
    "\n",
    "df = df.applymap(replace_zeros)\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bohužel. ruční kategorizace pomocí vlastního definování hranic a názvů kategorií"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FVE\n",
    "bins = [-1, 50, 300, 400, 500, 602]\n",
    "bins2 = [-1, 50, 270, 350, 440, 506]\n",
    "bins3 = [-1, 0.1, 3, 7, 10, 15.4]\n",
    "bins4 = [-1, 15, 500, 1500, 3000, 4500, 6010]\n",
    "bins5 = [-1, 15, 500, 1000, 2750, 4000, 5800]\n",
    "bins6 = [-500, -1, 1, 1000, 3000, 5000, 7000, 12000]\n",
    "bins7 = [-10500, -7500, -5000, -2500, -1000, -1, 1, 1000, 3000, 5000, 7000, 12000]\n",
    "\n",
    "labels = ['Nula', 'Extremely Low', 'Low', 'Normal', 'High']\n",
    "labels2 = ['Nula', 'A<3', '3<A<7', '7<A<10', '10<A<15.4']\n",
    "labels3 = ['Nula', 'Extremely Low', 'Low', 'Normal', 'High', 'Very High']\n",
    "labels4 = ['Negative', 'Nula', 'Extremely Low', 'Low', 'Normal', 'High', 'Very High']\n",
    "labels5 = ['Neg Very High', 'Neg High', 'Neg Normal', 'Neg Low', 'Neg Extremely Low',\n",
    " 'Nula', 'Extremely Low', 'Low', 'Normal', 'High', 'Very High']\n",
    "\n",
    "df['PV1_voltage_(V)_cat'] = pd.cut(df['PV1 voltage (V)'], bins=bins, labels=labels)\n",
    "df['PV2_voltage_(V)_cat'] = pd.cut(df['PV2 voltage (V)'], bins=bins2, labels=labels)\n",
    "df['PV1_current_(A)_cat'] = pd.cut(df['PV1 current (A)'], bins=bins3, labels=labels2)\n",
    "df['PV2_current_(A)_cat'] = pd.cut(df['PV2 current (A)'], bins=bins3, labels=labels2)\n",
    "df['PV1_input_power(W)_cat'] = pd.cut(df['PV1 input power(W)'], bins=bins4, labels=labels3)\n",
    "df['PV2_input_power(W)_cat'] = pd.cut(df['PV2 input power(W)'], bins=bins5, labels=labels3)\n",
    "df['output_power(W)_cat'] = pd.cut(df['output power(W)'], bins=bins6, labels=labels4)\n",
    "df['feed-in_power(W)_cat'] = pd.cut(df['feed-in power(W)'], bins=bins7, labels=labels5)\n",
    "\n",
    "#pocasi\n",
    "bin = [-14, -10, -5, 0, 5, 10, 15, 20, 25, 30, 35, 37]\n",
    "bin1 = [-15, -10, -5, 0, 5, 10, 15, 20, 25]\n",
    "bin2 = [20, 40, 60, 80, 100]\n",
    "bin3 = [-1, 2.5, 5, 10, 15, 20]\n",
    "bin4 = [-1, 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 40, 60, 80, 100]\n",
    "bin5 = [-1, 1, 100]\n",
    "\n",
    "label = ['<-10', '-10 až -5', '-5 až 0', '0 až 5', '5 až 10', '10 až 15', '15 až 20', '20 až 25', '25 až 30', '30 až 35', '>35']\n",
    "label1 = ['<-10', '-10 až -5', '-5 až 0', '0 až 5', '5 až 10', '10 až 15', '15 až 20', '20 až 25']\n",
    "label2 = ['20-39', '40-59', '60-79', '80-99']\n",
    "label3 = ['0-2.5','2.5-5', '5-9', '10-14', '15-19']\n",
    "label4 = ['0', '0.1-0.19', '0.2-0.49', '0.5-0.99', '1-1.99', '2-4.99', '5-9.99', '10-19.99', '20-39.99', '40-59.99', '60-79.99', '80-99.99']\n",
    "label5 = ['neprší', \"prší\"]\n",
    "\n",
    "df['Temperature_cat'] = pd.cut(df['Temperature_C'], bins=bin, labels=label, include_lowest=True)\n",
    "df['Dew_Point_C_cat'] = pd.cut(df['Dew_Point_C'], bins=bin1, labels=label1, include_lowest=True)\n",
    "df['Humidity_%_cat'] = pd.cut(df['Humidity_%'], bins=bin2, labels=label2, include_lowest=True)\n",
    "df['Speed_kmh_cat'] = pd.cut(df['Speed_kmh'], bins=bin3, labels=label3, include_lowest=True)\n",
    "df['Precip_Rate_mm_cat'] = pd.cut(df['Precip_Rate_mm'], bins=bin4, labels=label4, include_lowest=True)\n",
    "df['prší?'] = pd.cut(df['Precip_Rate_mm'], bins=bin5, labels=label5, include_lowest=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vytvoření sloupců s informací o dni v týdnu a hodině a zdali se jedná o pracovní den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "# 0=Monday, 6=Sunday\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "\n",
    "df['is_workday'] = df['day_of_week'].apply(lambda x: \"pracovní den\" if x < 5 else \"víkend\")\n",
    "\n",
    "df.to_csv('finalintoclever.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CleverMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverminer import cleverminer as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['Inverter Status','Battery operating status','PV1_voltage_(V)_cat','PV2_voltage_(V)_cat',\n",
    "'PV1_current_(A)_cat','PV2_current_(A)_cat','PV1_input_power(W)_cat','PV2_input_power(W)_cat',\n",
    "'output_power(W)_cat','feed-in_power(W)_cat','Temperature_cat','Dew_Point_C_cat','Humidity_%_cat',\n",
    "'Speed_kmh_cat','Precip_Rate_mm_cat','prší?','hour','day_of_week','is_workday','month']\n",
    "\n",
    "mask = (df['PV1_voltage_(V)_cat'] != 'Nula') & (df['PV2_voltage_(V)_cat'] != 'Nula')\n",
    "\n",
    "df_copy = df.loc[mask, columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('daily.csv')\n",
    "\n",
    "# Initialize label encoders for each numerical attribute\n",
    "label_encoders = {col: LabelEncoder() for col in data.columns if data[col].dtype == 'float64'}\n",
    "\n",
    "# Define symmetrical bins and labels\n",
    "bins = np.linspace(0, 1, num=6)  # Creates 5 equal-width bins from 0 to 1\n",
    "labels = ['extremely low', 'low', 'medium', 'high', 'extremely high']\n",
    "\n",
    "# Fit and transform the numerical attributes\n",
    "for col, le in label_encoders.items():\n",
    "    # Scale the data to [0, 1] range\n",
    "    data[col + '_scaled'] = (data[col] - data[col].min()) / (data[col].max() - data[col].min())\n",
    "    # Use pandas cut function to apply the binning\n",
    "    data[col + '_binned'] = pd.cut(data[col + '_scaled'], bins=bins, labels=labels, include_lowest=True)\n",
    "    # Encode the binned data\n",
    "    data[col + '_encoded'] = le.fit_transform(data[col + '_binned'])\n",
    "\n",
    "# Extract day of week, hours, and month from the timestamp\n",
    "data['day_of_week'] = data['timestamp'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d').weekday())\n",
    "data['month'] = data['timestamp'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d').month)\n",
    "\n",
    "# Extract hours from time features\n",
    "time_features = ['peak_production_time', 'peak_PV1_production_time', 'peak_PV2_production_time', 'peak_feed_inpower_time', 'low_feed_inpower_time']\n",
    "for feature in time_features:\n",
    "    data[feature + '_hour'] = data[feature].apply(lambda x: datetime.strptime(x, '%H:%M:%S').hour)\n",
    "\n",
    "# Drop the original time columns and scaled columns\n",
    "data.drop(columns=time_features + [col for col in data.columns if 'scaled' in col], inplace=True)\n",
    "\n",
    "# Save the new dataset\n",
    "data.to_csv('new_dataset_encoded.csv', index=False)\n",
    "\n",
    "# Create a copy with only the constructed columns\n",
    "constructed_columns = ['day_of_week', 'month'] + [col + '_binned' for col in label_encoders.keys()] + [feature + '_hour' for feature in time_features]\n",
    "constructed_data = data[constructed_columns].copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4FTMINER #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleverminer version 1.0.8.\n",
      "Starting data preparation ...\n",
      "Automatically reordering numeric categories ...\n",
      "Encoding columns into bit-form...\n",
      "Encoding columns into bit-form...done\n",
      "Data preparation finished.\n",
      "Will go for  4ftMiner\n",
      "Starting to mine rules.\n",
      "  0%|                                                    |Elapsed Time: 0:00:00\n",
      "  5%|##                                                  |Elapsed Time: 0:00:00\n",
      "  9%|####                                                |Elapsed Time: 0:00:00\n",
      " 13%|#######                                             |Elapsed Time: 0:00:00\n",
      " 17%|#########                                           |Elapsed Time: 0:00:00\n",
      " 21%|###########                                         |Elapsed Time: 0:00:00\n",
      " 26%|#############                                       |Elapsed Time: 0:00:00\n",
      " 29%|###############                                     |Elapsed Time: 0:00:00\n",
      " 34%|#################                                   |Elapsed Time: 0:00:00\n",
      " 36%|##################                                  |Elapsed Time: 0:00:00\n",
      " 39%|####################                                |Elapsed Time: 0:00:00\n",
      " 42%|######################                              |Elapsed Time: 0:00:00\n",
      " 46%|########################                            |Elapsed Time: 0:00:00\n",
      "100%|####################################################|Elapsed Time: 0:00:00\n",
      "Done. Total verifications : 6831, rules 6, times: prep 0.66sec, processing 0.75sec\n",
      "\n",
      "CleverMiner task processing summary:\n",
      "\n",
      "Task type : 4ftMiner\n",
      "Number of verifications : 6831\n",
      "Number of rules : 6\n",
      "Total time needed : 00h 00m 01s\n",
      "Time of data preparation : 00h 00m 00s\n",
      "Time of rule mining : 00h 00m 00s\n",
      "\n",
      "\n",
      "List of rules:\n",
      "RULEID BASE  CONF  AAD    Rule\n",
      "     1   252 0.824 +14.740 hour(6 7 8) & month(1) => feed-in_power(W)_cat(Neg Very High Neg High Neg Normal) | ---\n",
      "     2   202 0.737 +13.090 hour(6 7 8) & month(12) => feed-in_power(W)_cat(Neg Very High Neg High Neg Normal) | ---\n",
      "     3   252 0.824 +14.740 hour(7 8) & month(1) => feed-in_power(W)_cat(Neg Very High Neg High Neg Normal) | ---\n",
      "     4   202 0.737 +13.090 hour(7 8) & month(12) => feed-in_power(W)_cat(Neg Very High Neg High Neg Normal) | ---\n",
      "     5   252 0.875 +15.724 hour(8) & month(1) => feed-in_power(W)_cat(Neg Very High Neg High Neg Normal) | ---\n",
      "     6   200 0.766 +13.646 hour(8) & month(12) => feed-in_power(W)_cat(Neg Very High Neg High Neg Normal) | ---\n",
      "\n",
      "\n",
      "\n",
      "Rule id : 1\n",
      "\n",
      "Base :   252  Relative base : 0.004  CONF : 0.824  AAD : +14.740  BAD : -14.740\n",
      "\n",
      "Cedents:\n",
      "  antecedent : hour(6 7 8) & month(1)\n",
      "  succcedent : feed-in_power(W)_cat(Neg Very High Neg High Neg Normal)\n",
      "  condition  : ---\n",
      "\n",
      "Fourfold table\n",
      "    |  S  |  ¬S |\n",
      "----|-----|-----|\n",
      " A  |  252|   54|\n",
      "----|-----|-----|\n",
      "¬A  | 2799|55208|\n",
      "----|-----|-----|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clm = cm(df=df_copy,proc='4ftMiner',\n",
    "               quantifiers= {'Conf': 0.70},\n",
    "               ante ={\n",
    "                    'attributes':[\n",
    "                        {'name': 'hour', 'type': 'seq', 'minlen': 1, 'maxlen': 3},\n",
    "                        {'name': 'month', 'type': 'seq', 'minlen': 1, 'maxlen': 3},\n",
    "                    ], 'minlen':2, 'maxlen':2, 'type':'con'},\n",
    "               succ ={\n",
    "                    'attributes':[\n",
    "                        {'name': 'feed-in_power(W)_cat', 'type': 'lcut', 'minlen': 1, 'maxlen': 3}\n",
    "                    ], 'minlen':1, 'maxlen':1, 'type':'con'},\n",
    "               )\n",
    "\n",
    "\n",
    "clm.print_summary()\n",
    "clm.print_rulelist()\n",
    "clm.print_rule(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4FTMINER #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleverminer version 1.0.8.\n",
      "Starting data preparation ...\n",
      "Automatically reordering numeric categories ...\n",
      "Encoding columns into bit-form...\n",
      "Encoding columns into bit-form...done\n",
      "Data preparation finished.\n",
      "Will go for  4ftMiner\n",
      "Starting to mine rules.\n",
      "  0%|                                                    |Elapsed Time: 0:00:00\n",
      "100%|####################################################|Elapsed Time: 0:00:00\n",
      "Done. Total verifications : 150, rules 11, times: prep 0.30sec, processing 0.03sec\n",
      "\n",
      "CleverMiner task processing summary:\n",
      "\n",
      "Task type : 4ftMiner\n",
      "Number of verifications : 150\n",
      "Number of rules : 11\n",
      "Total time needed : 00h 00m 00s\n",
      "Time of data preparation : 00h 00m 00s\n",
      "Time of rule mining : 00h 00m 00s\n",
      "\n",
      "\n",
      "List of rules:\n",
      "RULEID BASE  CONF  AAD    Rule\n",
      "     1   848 0.805 +0.715 PV1_current_(A)_cat(A<3) => PV1_input_power(W)_cat(Extremely Low) | PV1_voltage_(V)_cat(Extremely Low)\n",
      "     2   214 0.986 +7.453 PV1_current_(A)_cat(3<A<7) => PV1_input_power(W)_cat(Low) | PV1_voltage_(V)_cat(Extremely Low)\n",
      "     3     4 1.000 +299.000 PV1_current_(A)_cat(7<A<10) => PV1_input_power(W)_cat(Normal) | PV1_voltage_(V)_cat(Extremely Low)\n",
      "     4  2879 0.801 +0.169 PV1_current_(A)_cat(A<3) => PV1_input_power(W)_cat(Extremely Low) | PV1_voltage_(V)_cat(Low)\n",
      "     5    19 0.905 +192.167 PV1_current_(A)_cat(7<A<10) => PV1_input_power(W)_cat(High) | PV1_voltage_(V)_cat(Low)\n",
      "     6  1408 0.891 +1.884 PV1_current_(A)_cat(Nula) => PV1_input_power(W)_cat(Extremely Low) | PV1_voltage_(V)_cat(Normal)\n",
      "     7  8648 0.824 +3.056 PV1_current_(A)_cat(3<A<7) => PV1_input_power(W)_cat(Normal) | PV1_voltage_(V)_cat(Normal)\n",
      "     8  5808 0.964 +4.525 PV1_current_(A)_cat(7<A<10) => PV1_input_power(W)_cat(High) | PV1_voltage_(V)_cat(Normal)\n",
      "     9   916 0.807 +29.631 PV1_current_(A)_cat(10<A<15.4) => PV1_input_power(W)_cat(Very High) | PV1_voltage_(V)_cat(Normal)\n",
      "    10  1232 0.930 +2.597 PV1_current_(A)_cat(3<A<7) => PV1_input_power(W)_cat(Normal) | PV1_voltage_(V)_cat(High)\n",
      "    11     5 1.000 +315.765 PV1_current_(A)_cat(10<A<15.4) => PV1_input_power(W)_cat(Very High) | PV1_voltage_(V)_cat(High)\n",
      "\n",
      "\n",
      "\n",
      "Rule id : 9\n",
      "\n",
      "Base :   916  Relative base : 0.016  CONF : 0.807  AAD : +29.631  BAD : -29.631\n",
      "\n",
      "Cedents:\n",
      "  antecedent : PV1_current_(A)_cat(10<A<15.4)\n",
      "  succcedent : PV1_input_power(W)_cat(Very High)\n",
      "  condition  : PV1_voltage_(V)_cat(Normal)\n",
      "\n",
      "Fourfold table\n",
      "    |  S  |  ¬S |\n",
      "----|-----|-----|\n",
      " A  |  916|  219|\n",
      "----|-----|-----|\n",
      "¬A  |  212|41465|\n",
      "----|-----|-----|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clm = cm(df=df_copy,proc='4ftMiner',\n",
    "               quantifiers= {'Conf':0.8},\n",
    "               ante ={\n",
    "                    'attributes':[\n",
    "                        {'name': 'PV1_current_(A)_cat', 'type': 'subset', 'minlen': 1, 'maxlen': 1},\n",
    "                    ], 'minlen':1, 'maxlen':2, 'type':'con'},\n",
    "               succ ={\n",
    "                    'attributes':[\n",
    "                        {'name': 'PV1_input_power(W)_cat', 'type': 'subset', 'minlen': 1, 'maxlen': 1} \n",
    "                    ], 'minlen':1, 'maxlen':2, 'type':'con'},\n",
    "                cond ={\n",
    "                    'attributes':[\n",
    "                        {'name': 'PV1_voltage_(V)_cat', 'type': 'subset', 'minlen': 1, 'maxlen': 1},\n",
    "                    ], 'minlen':1, 'maxlen':1, 'type':'con'}\n",
    "               )\n",
    "\n",
    "\n",
    "clm.print_summary()\n",
    "clm.print_rulelist()\n",
    "clm.print_rule(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleverminer version 1.0.8.\n",
      "Starting data preparation ...\n",
      "Automatically reordering numeric categories ...\n",
      "Encoding columns into bit-form...\n",
      "Encoding columns into bit-form...done\n",
      "Data preparation finished.\n",
      "Will go for  CFMiner\n",
      "Starting to mine rules.\n",
      "  0%|                                                    |Elapsed Time: 0:00:00\n",
      " 15%|#######                                             |Elapsed Time: 0:00:00\n",
      " 39%|####################                                |Elapsed Time: 0:00:00\n",
      "100%|####################################################|Elapsed Time: 0:00:00\n",
      "Done. Total verifications : 1585, rules 1, times: prep 0.25sec, processing 0.16sec\n",
      "\n",
      "CleverMiner task processing summary:\n",
      "\n",
      "Task type : CFMiner\n",
      "Number of verifications : 1585\n",
      "Number of rules : 1\n",
      "Total time needed : 00h 00m 00s\n",
      "Time of data preparation : 00h 00m 00s\n",
      "Time of rule mining : 00h 00m 00s\n",
      "\n",
      "\n",
      "List of rules:\n",
      "RULEID BASE  S_UP  S_DOWN Condition\n",
      "     1  5826     4     1 month(5)\n",
      "\n",
      "\n",
      "\n",
      "Rule id : 1\n",
      "\n",
      "Base :  5826  Relative base : 0.100  Steps UP (consecutive) :     4  Steps DOWN (consecutive) :     1  Steps UP (any) :     4  Steps DOWN (any) :     1  Histogram maximum :  1327  Histogram minimum :   120  Histogram relative maximum : 0.238 Histogram relative minimum : 0.022 \n",
      "\n",
      "Condition  : month(5)\n",
      "\n",
      "Categories in target variable  ['Nula', 'Extremely Low', 'Low', 'Normal', 'High', 'Very High']\n",
      "Histogram                      [120, 1277, 1289, 1300, 1327, 251]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clm = cm(df=df_copy,target='PV1_input_power(W)_cat',proc='CFMiner',\n",
    "               quantifiers= {'S_Up':4},\n",
    "               cond ={\n",
    "                    'attributes':[\n",
    "                        {'name': 'month', 'type': 'subset', 'minlen': 1, 'maxlen': 5},\n",
    "                    ], 'minlen':1, 'maxlen':1, 'type':'con'}\n",
    "               )\n",
    "\n",
    "\n",
    "clm.print_summary()\n",
    "clm.print_rulelist()\n",
    "clm.print_rule(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleverminer version 1.0.8.\n",
      "Starting data preparation ...\n",
      "Automatically reordering numeric categories ...\n",
      "Encoding columns into bit-form...\n",
      "Encoding columns into bit-form...done\n",
      "Data preparation finished.\n",
      "Will go for  4ftMiner\n",
      "Starting to mine rules.\n",
      "  0%|                                                    |Elapsed Time: 0:00:00\n",
      "100%|####################################################|Elapsed Time: 0:00:00\n",
      "Done. Total verifications : 156, rules 156, times: prep 0.04sec, processing 0.06sec\n",
      "\n",
      "CleverMiner task processing summary:\n",
      "\n",
      "Task type : 4ftMiner\n",
      "Number of verifications : 156\n",
      "Number of rules : 156\n",
      "Total time needed : 00h 00m 00s\n",
      "Time of data preparation : 00h 00m 00s\n",
      "Time of rule mining : 00h 00m 00s\n",
      "\n",
      "\n",
      "List of rules:\n",
      "RULEID BASE  CONF  AAD    Rule\n",
      "     1     5 0.500 +0.292 day_of_week(0 1) => daily_consumption_binned(high) | month(1)\n",
      "     2     5 0.333 +0.033 day_of_week(0 1 2) => daily_consumption_binned(medium) | month(1)\n",
      "     3     6 0.400 +0.033 day_of_week(0 1 2) => daily_consumption_binned(high) | month(1)\n",
      "     4     5 0.357 +0.107 day_of_week(1 2 3) => daily_consumption_binned(medium) | month(1)\n",
      "     5     5 0.357 +0.230 day_of_week(1 2 3) => daily_consumption_binned(extremely high) | month(1)\n",
      "     6     6 0.462 +0.431 day_of_week(2 3 4) => daily_consumption_binned(medium) | month(1)\n",
      "     7     6 0.462 +0.590 day_of_week(2 3 4) => daily_consumption_binned(extremely high) | month(1)\n",
      "     8     5 0.417 +0.435 day_of_week(3 4 5) => daily_consumption_binned(extremely high) | month(1)\n",
      "     9     6 0.500 +0.292 day_of_week(4 5 6) => daily_consumption_binned(high) | month(1)\n",
      "    10     6 0.750 +0.938 day_of_week(5 6) => daily_consumption_binned(high) | month(1)\n",
      "    11     5 0.417 +0.098 day_of_week(0 1 2) => daily_consumption_binned(low) | month(2)\n",
      "    12     6 0.500 +0.036 day_of_week(0 1 2) => daily_consumption_binned(medium) | month(2)\n",
      "    13     7 0.538 +0.115 day_of_week(1 2 3) => daily_consumption_binned(medium) | month(2)\n",
      "    14     6 0.667 +0.381 day_of_week(2 3) => daily_consumption_binned(medium) | month(2)\n",
      "    15     7 0.538 +0.115 day_of_week(2 3 4) => daily_consumption_binned(medium) | month(2)\n",
      "    16     5 0.385 +0.014 day_of_week(3 4 5) => daily_consumption_binned(low) | month(2)\n",
      "    17     5 0.385 -0.203 day_of_week(3 4 5) => daily_consumption_binned(medium) | month(2)\n",
      "    18     5 0.625 +0.648 day_of_week(4 5) => daily_consumption_binned(low) | month(2)\n",
      "    19     6 0.500 +0.318 day_of_week(4 5 6) => daily_consumption_binned(low) | month(2)\n",
      "    20     5 0.417 -0.137 day_of_week(4 5 6) => daily_consumption_binned(medium) | month(2)\n",
      "    21     6 0.500 -0.161 day_of_week(0 1) => daily_consumption_binned(extremely low) | month(3)\n",
      "    22     6 0.500 +0.306 day_of_week(0 1) => daily_consumption_binned(low) | month(3)\n",
      "    23    10 0.556 -0.067 day_of_week(0 1 2) => daily_consumption_binned(extremely low) | month(3)\n",
      "    24     8 0.444 +0.160 day_of_week(0 1 2) => daily_consumption_binned(low) | month(3)\n",
      "    25     7 0.583 -0.021 day_of_week(1 2) => daily_consumption_binned(extremely low) | month(3)\n",
      "    26     5 0.417 +0.088 day_of_week(1 2) => daily_consumption_binned(low) | month(3)\n",
      "    27    11 0.579 -0.028 day_of_week(1 2 3) => daily_consumption_binned(extremely low) | month(3)\n",
      "    28     8 0.421 +0.099 day_of_week(1 2 3) => daily_consumption_binned(low) | month(3)\n",
      "    29     8 0.615 +0.033 day_of_week(2 3) => daily_consumption_binned(extremely low) | month(3)\n",
      "    30     5 0.385 +0.004 day_of_week(2 3) => daily_consumption_binned(low) | month(3)\n",
      "    31    13 0.619 +0.039 day_of_week(2 3 4) => daily_consumption_binned(extremely low) | month(3)\n",
      "    32     8 0.381 -0.005 day_of_week(2 3 4) => daily_consumption_binned(low) | month(3)\n",
      "    33     9 0.600 +0.007 day_of_week(3 4) => daily_consumption_binned(extremely low) | month(3)\n",
      "    34     6 0.400 +0.044 day_of_week(3 4) => daily_consumption_binned(low) | month(3)\n",
      "    35    13 0.591 -0.008 day_of_week(3 4 5) => daily_consumption_binned(extremely low) | month(3)\n",
      "    36     8 0.364 -0.051 day_of_week(3 4 5) => daily_consumption_binned(low) | month(3)\n",
      "    37     5 0.625 +0.049 day_of_week(4) => daily_consumption_binned(extremely low) | month(3)\n",
      "    38     9 0.600 +0.007 day_of_week(4 5) => daily_consumption_binned(extremely low) | month(3)\n",
      "    39     5 0.333 -0.130 day_of_week(4 5) => daily_consumption_binned(low) | month(3)\n",
      "    40    14 0.636 +0.068 day_of_week(4 5 6) => daily_consumption_binned(extremely low) | month(3)\n",
      "    41     7 0.318 -0.169 day_of_week(4 5 6) => daily_consumption_binned(low) | month(3)\n",
      "    42     9 0.643 +0.079 day_of_week(5 6) => daily_consumption_binned(extremely low) | month(3)\n",
      "    43     5 0.714 +0.199 day_of_week(6) => daily_consumption_binned(extremely low) | month(3)\n",
      "    44     7 1.000 +0.122 day_of_week(0) => daily_consumption_binned(extremely low) | month(4)\n",
      "    45    14 1.000 +0.122 day_of_week(0 1) => daily_consumption_binned(extremely low) | month(4)\n",
      "    46    20 1.000 +0.122 day_of_week(0 1 2) => daily_consumption_binned(extremely low) | month(4)\n",
      "    47     7 1.000 +0.122 day_of_week(1) => daily_consumption_binned(extremely low) | month(4)\n",
      "    48    13 1.000 +0.122 day_of_week(1 2) => daily_consumption_binned(extremely low) | month(4)\n",
      "    49    19 1.000 +0.122 day_of_week(1 2 3) => daily_consumption_binned(extremely low) | month(4)\n",
      "    50     6 1.000 +0.122 day_of_week(2) => daily_consumption_binned(extremely low) | month(4)\n",
      "    51    12 1.000 +0.122 day_of_week(2 3) => daily_consumption_binned(extremely low) | month(4)\n",
      "    52    16 0.889 -0.003 day_of_week(2 3 4) => daily_consumption_binned(extremely low) | month(4)\n",
      "    53     6 1.000 +0.122 day_of_week(3) => daily_consumption_binned(extremely low) | month(4)\n",
      "    54    10 0.833 -0.065 day_of_week(3 4) => daily_consumption_binned(extremely low) | month(4)\n",
      "    55    15 0.789 -0.114 day_of_week(3 4 5) => daily_consumption_binned(extremely low) | month(4)\n",
      "    56     9 0.692 -0.223 day_of_week(4 5) => daily_consumption_binned(extremely low) | month(4)\n",
      "    57    15 0.750 -0.159 day_of_week(4 5 6) => daily_consumption_binned(extremely low) | month(4)\n",
      "    58     5 0.714 -0.199 day_of_week(5) => daily_consumption_binned(extremely low) | month(4)\n",
      "    59    11 0.786 -0.118 day_of_week(5 6) => daily_consumption_binned(extremely low) | month(4)\n",
      "    60     6 0.857 -0.038 day_of_week(6) => daily_consumption_binned(extremely low) | month(4)\n",
      "    61     5 1.000 +0.000 day_of_week(0) => daily_consumption_binned(extremely low) | month(5)\n",
      "    62    10 1.000 +0.000 day_of_week(0 1) => daily_consumption_binned(extremely low) | month(5)\n",
      "    63    15 1.000 +0.000 day_of_week(0 1 2) => daily_consumption_binned(extremely low) | month(5)\n",
      "    64     5 1.000 +0.000 day_of_week(1) => daily_consumption_binned(extremely low) | month(5)\n",
      "    65    10 1.000 +0.000 day_of_week(1 2) => daily_consumption_binned(extremely low) | month(5)\n",
      "    66    14 1.000 +0.000 day_of_week(1 2 3) => daily_consumption_binned(extremely low) | month(5)\n",
      "    67     5 1.000 +0.000 day_of_week(2) => daily_consumption_binned(extremely low) | month(5)\n",
      "    68     9 1.000 +0.000 day_of_week(2 3) => daily_consumption_binned(extremely low) | month(5)\n",
      "    69    13 1.000 +0.000 day_of_week(2 3 4) => daily_consumption_binned(extremely low) | month(5)\n",
      "    70     8 1.000 +0.000 day_of_week(3 4) => daily_consumption_binned(extremely low) | month(5)\n",
      "    71    12 1.000 +0.000 day_of_week(3 4 5) => daily_consumption_binned(extremely low) | month(5)\n",
      "    72     8 1.000 +0.000 day_of_week(4 5) => daily_consumption_binned(extremely low) | month(5)\n",
      "    73    12 1.000 +0.000 day_of_week(4 5 6) => daily_consumption_binned(extremely low) | month(5)\n",
      "    74     8 1.000 +0.000 day_of_week(5 6) => daily_consumption_binned(extremely low) | month(5)\n",
      "    75     8 1.000 +0.000 day_of_week(0 1) => daily_consumption_binned(extremely low) | month(6)\n",
      "    76    12 1.000 +0.000 day_of_week(0 1 2) => daily_consumption_binned(extremely low) | month(6)\n",
      "    77     8 1.000 +0.000 day_of_week(1 2) => daily_consumption_binned(extremely low) | month(6)\n",
      "    78    13 1.000 +0.000 day_of_week(1 2 3) => daily_consumption_binned(extremely low) | month(6)\n",
      "    79     9 1.000 +0.000 day_of_week(2 3) => daily_consumption_binned(extremely low) | month(6)\n",
      "    80    14 1.000 +0.000 day_of_week(2 3 4) => daily_consumption_binned(extremely low) | month(6)\n",
      "    81     5 1.000 +0.000 day_of_week(3) => daily_consumption_binned(extremely low) | month(6)\n",
      "    82    10 1.000 +0.000 day_of_week(3 4) => daily_consumption_binned(extremely low) | month(6)\n",
      "    83    14 1.000 +0.000 day_of_week(3 4 5) => daily_consumption_binned(extremely low) | month(6)\n",
      "    84     5 1.000 +0.000 day_of_week(4) => daily_consumption_binned(extremely low) | month(6)\n",
      "    85     9 1.000 +0.000 day_of_week(4 5) => daily_consumption_binned(extremely low) | month(6)\n",
      "    86    13 1.000 +0.000 day_of_week(4 5 6) => daily_consumption_binned(extremely low) | month(6)\n",
      "    87     8 1.000 +0.000 day_of_week(5 6) => daily_consumption_binned(extremely low) | month(6)\n",
      "    88     5 1.000 +0.000 day_of_week(0) => daily_consumption_binned(extremely low) | month(7)\n",
      "    89     9 1.000 +0.000 day_of_week(0 1) => daily_consumption_binned(extremely low) | month(7)\n",
      "    90    13 1.000 +0.000 day_of_week(0 1 2) => daily_consumption_binned(extremely low) | month(7)\n",
      "    91     8 1.000 +0.000 day_of_week(1 2) => daily_consumption_binned(extremely low) | month(7)\n",
      "    92    12 1.000 +0.000 day_of_week(1 2 3) => daily_consumption_binned(extremely low) | month(7)\n",
      "    93     8 1.000 +0.000 day_of_week(2 3) => daily_consumption_binned(extremely low) | month(7)\n",
      "    94    12 1.000 +0.000 day_of_week(2 3 4) => daily_consumption_binned(extremely low) | month(7)\n",
      "    95     8 1.000 +0.000 day_of_week(3 4) => daily_consumption_binned(extremely low) | month(7)\n",
      "    96    13 1.000 +0.000 day_of_week(3 4 5) => daily_consumption_binned(extremely low) | month(7)\n",
      "    97     9 1.000 +0.000 day_of_week(4 5) => daily_consumption_binned(extremely low) | month(7)\n",
      "    98    14 1.000 +0.000 day_of_week(4 5 6) => daily_consumption_binned(extremely low) | month(7)\n",
      "    99     5 1.000 +0.000 day_of_week(5) => daily_consumption_binned(extremely low) | month(7)\n",
      "   100    10 1.000 +0.000 day_of_week(5 6) => daily_consumption_binned(extremely low) | month(7)\n",
      "   101     5 1.000 +0.000 day_of_week(6) => daily_consumption_binned(extremely low) | month(7)\n",
      "   102     8 0.889 -0.081 day_of_week(0 1) => daily_consumption_binned(extremely low) | month(8)\n",
      "   103    13 0.929 -0.040 day_of_week(0 1 2) => daily_consumption_binned(extremely low) | month(8)\n",
      "   104     9 0.900 -0.070 day_of_week(1 2) => daily_consumption_binned(extremely low) | month(8)\n",
      "   105    14 0.933 -0.036 day_of_week(1 2 3) => daily_consumption_binned(extremely low) | month(8)\n",
      "   106     5 1.000 +0.033 day_of_week(2) => daily_consumption_binned(extremely low) | month(8)\n",
      "   107    10 1.000 +0.033 day_of_week(2 3) => daily_consumption_binned(extremely low) | month(8)\n",
      "   108    14 1.000 +0.033 day_of_week(2 3 4) => daily_consumption_binned(extremely low) | month(8)\n",
      "   109     5 1.000 +0.033 day_of_week(3) => daily_consumption_binned(extremely low) | month(8)\n",
      "   110     9 1.000 +0.033 day_of_week(3 4) => daily_consumption_binned(extremely low) | month(8)\n",
      "   111    13 1.000 +0.033 day_of_week(3 4 5) => daily_consumption_binned(extremely low) | month(8)\n",
      "   112     8 1.000 +0.033 day_of_week(4 5) => daily_consumption_binned(extremely low) | month(8)\n",
      "   113    12 1.000 +0.033 day_of_week(4 5 6) => daily_consumption_binned(extremely low) | month(8)\n",
      "   114     8 1.000 +0.033 day_of_week(5 6) => daily_consumption_binned(extremely low) | month(8)\n",
      "   115     8 1.000 +0.000 day_of_week(0 1) => daily_consumption_binned(extremely low) | month(9)\n",
      "   116    12 1.000 +0.000 day_of_week(0 1 2) => daily_consumption_binned(extremely low) | month(9)\n",
      "   117     8 1.000 +0.000 day_of_week(1 2) => daily_consumption_binned(extremely low) | month(9)\n",
      "   118    12 1.000 +0.000 day_of_week(1 2 3) => daily_consumption_binned(extremely low) | month(9)\n",
      "   119     8 1.000 +0.000 day_of_week(2 3) => daily_consumption_binned(extremely low) | month(9)\n",
      "   120    13 1.000 +0.000 day_of_week(2 3 4) => daily_consumption_binned(extremely low) | month(9)\n",
      "   121     9 1.000 +0.000 day_of_week(3 4) => daily_consumption_binned(extremely low) | month(9)\n",
      "   122    14 1.000 +0.000 day_of_week(3 4 5) => daily_consumption_binned(extremely low) | month(9)\n",
      "   123     5 1.000 +0.000 day_of_week(4) => daily_consumption_binned(extremely low) | month(9)\n",
      "   124    10 1.000 +0.000 day_of_week(4 5) => daily_consumption_binned(extremely low) | month(9)\n",
      "   125    14 1.000 +0.000 day_of_week(4 5 6) => daily_consumption_binned(extremely low) | month(9)\n",
      "   126     5 1.000 +0.000 day_of_week(5) => daily_consumption_binned(extremely low) | month(9)\n",
      "   127     9 1.000 +0.000 day_of_week(5 6) => daily_consumption_binned(extremely low) | month(9)\n",
      "   128     7 0.700 -0.132 day_of_week(0 1) => daily_consumption_binned(extremely low) | month(10)\n",
      "   129    11 0.786 -0.026 day_of_week(0 1 2) => daily_consumption_binned(extremely low) | month(10)\n",
      "   130     7 0.778 -0.036 day_of_week(1 2) => daily_consumption_binned(extremely low) | month(10)\n",
      "   131    10 0.769 -0.046 day_of_week(1 2 3) => daily_consumption_binned(extremely low) | month(10)\n",
      "   132     7 0.875 +0.085 day_of_week(2 3) => daily_consumption_binned(extremely low) | month(10)\n",
      "   133    10 0.833 +0.033 day_of_week(2 3 4) => daily_consumption_binned(extremely low) | month(10)\n",
      "   134     6 0.750 -0.070 day_of_week(3 4) => daily_consumption_binned(extremely low) | month(10)\n",
      "   135     9 0.750 -0.070 day_of_week(3 4 5) => daily_consumption_binned(extremely low) | month(10)\n",
      "   136     6 0.750 -0.070 day_of_week(4 5) => daily_consumption_binned(extremely low) | month(10)\n",
      "   137    11 0.846 +0.049 day_of_week(4 5 6) => daily_consumption_binned(extremely low) | month(10)\n",
      "   138     8 0.889 +0.102 day_of_week(5 6) => daily_consumption_binned(extremely low) | month(10)\n",
      "   139     5 1.000 +0.240 day_of_week(6) => daily_consumption_binned(extremely low) | month(10)\n",
      "   140     5 0.385 +0.154 day_of_week(0 1 2) => daily_consumption_binned(low) | month(11)\n",
      "   141     5 0.357 +0.071 day_of_week(1 2 3) => daily_consumption_binned(low) | month(11)\n",
      "   142     5 0.357 +0.071 day_of_week(2 3 4) => daily_consumption_binned(low) | month(11)\n",
      "   143     6 0.462 +0.538 day_of_week(3 4 5) => daily_consumption_binned(medium) | month(11)\n",
      "   144     5 0.625 +1.083 day_of_week(4 5) => daily_consumption_binned(medium) | month(11)\n",
      "   145     6 0.500 +0.667 day_of_week(4 5 6) => daily_consumption_binned(medium) | month(11)\n",
      "   146     6 0.750 +0.292 day_of_week(0 1) => daily_consumption_binned(medium) | month(12)\n",
      "   147     9 0.750 +0.292 day_of_week(0 1 2) => daily_consumption_binned(medium) | month(12)\n",
      "   148     6 0.750 +0.292 day_of_week(1 2) => daily_consumption_binned(medium) | month(12)\n",
      "   149     9 0.750 +0.292 day_of_week(1 2 3) => daily_consumption_binned(medium) | month(12)\n",
      "   150     6 0.750 +0.292 day_of_week(2 3) => daily_consumption_binned(medium) | month(12)\n",
      "   151     7 0.538 -0.073 day_of_week(2 3 4) => daily_consumption_binned(medium) | month(12)\n",
      "   152     6 0.429 -0.262 day_of_week(3 4 5) => daily_consumption_binned(medium) | month(12)\n",
      "   153     5 0.357 +0.384 day_of_week(3 4 5) => daily_consumption_binned(extremely high) | month(12)\n",
      "   154     6 0.400 -0.311 day_of_week(4 5 6) => daily_consumption_binned(medium) | month(12)\n",
      "   155     5 0.333 +0.292 day_of_week(4 5 6) => daily_consumption_binned(extremely high) | month(12)\n",
      "   156     5 0.500 -0.139 day_of_week(5 6) => daily_consumption_binned(medium) | month(12)\n",
      "\n",
      "\n",
      "\n",
      "Rule id : 1\n",
      "\n",
      "Base :     5  Relative base : 0.013  CONF : 0.500  AAD : +0.292  BAD : -0.292\n",
      "\n",
      "Cedents:\n",
      "  antecedent : day_of_week(0 1)\n",
      "  succcedent : daily_consumption_binned(high)\n",
      "  condition  : month(1)\n",
      "\n",
      "Fourfold table\n",
      "    |  S  |  ¬S |\n",
      "----|-----|-----|\n",
      " A  |    5|    5|\n",
      "----|-----|-----|\n",
      "¬A  |    7|   14|\n",
      "----|-----|-----|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clm = cm(df=constructed_data,proc='4ftMiner',\n",
    "               quantifiers= {'Base':5},\n",
    "               ante ={\n",
    "                    'attributes':[\n",
    "                        {'name': 'day_of_week', 'type': 'seq', 'minlen': 1, 'maxlen': 3}\n",
    "                    ], 'minlen':1, 'maxlen':1, 'type':'con'},\n",
    "               succ ={\n",
    "                    'attributes':[\n",
    "                        {'name': 'daily_consumption_binned', 'type': 'subset', 'minlen': 1, 'maxlen':1},\n",
    "                    ], 'minlen':1, 'maxlen':1, 'type':'con'},\n",
    "                cond ={\n",
    "                    'attributes':[\n",
    "                        {'name': 'month', 'type': 'subset', 'minlen': 1, 'maxlen': 1},\n",
    "                    ], 'minlen':1, 'maxlen':2, 'type':'con'}\n",
    "               )\n",
    "\n",
    "clm.print_summary()\n",
    "clm.print_rulelist()\n",
    "clm.print_rule(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
